{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec85fce9",
   "metadata": {},
   "source": [
    "# Repeating Every Assessment/Experiment With 2.5D Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a20bf6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### <center> <i> <span style=\"color:green\"> Before we start... </span> </i> </center>\n",
    "\n",
    "As the title indicates, I'll be exploring results of using 2.5D classification, and comparing them with the replication of slices, in order to ascertain whether this approach is successful. \n",
    "\n",
    "Of course, these results will most likely be quite specific to my data set and methodologies, and will only represent a direct comparison and quality of my own methods.\n",
    "\n",
    "In order to maintain consistent cross-analysis results contrasts, each experiment will retain its original train-test-validation split and ResNet setup (architecture, settings, etc.).\n",
    "\n",
    "Additionally, I'll be avoiding some experimental comparisons, as they provided results that are guaranteed to be identical throughout both 2D and 2.5D classification. For example, I will not be using HRCT as the test split, nor testing whether the pure or conservative approach is best for best epoch choice. \n",
    "\n",
    "Still, all of this implies several code replications and re-executions. For this reason, I chose to display results in the form of a small report, with indexes and numbered titles, in order to facilitate comprehension and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380953fd",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [1. Data Augmentation vs No Augmentation](#1-data-augmentation-vs-no-augmentation)\n",
    "  - [1.1 Concept Overview](#11-concept-overview)\n",
    "  - [1.2 2.5D Execution of Data Augmentation vs No Augmentation](#13-25d-execution-of-data-augmentation-vs-no-augmentation)\n",
    "  - [1.3 Threshold Selection and Model Choice](#12-threshold-selection-and-model-choice)\n",
    "  - [1.4 Comparison with 2D](#14-comparison-with-2d)\n",
    "\n",
    "- [2. Patient-wise Classification Methods](#2-patient-wise-classification-methods)\n",
    "  - [2.1 Concept Overview](#21-concept-overview)\n",
    "  - [2.2 2.5D Execution of Patient-wise Classification Methods](#23-25d-execution-of-patient-wise-classification-methods)\n",
    "  - [2.3 Threshold Selection and Model Choice](#22-threshold-selection-and-model-choice)\n",
    "  - [2.4 Comparison with 2D](#24-comparison-with-2d)\n",
    "\n",
    "- [3. Slice-level Feature-wise Classification](#3-slice-level-feature-wise-classification)\n",
    "  - [3.1 Concept Overview](#31-concept-overview)\n",
    "  - [3.2 2.5D Execution of Slice-level Feature-wise Classification](#33-25d-execution-of-slice-level-feature-wise-classification)\n",
    "  - [3.3 Threshold Selection and Model Choice](#32-threshold-selection-and-model-choice)\n",
    "  - [3.4 Comparison with 2D](#34-comparison-with-2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d8a71",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Se for pior do que 2D em com e sem augmentation, tudo o que vem para baixo/dependente posso assumir que será pior também </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550709c",
   "metadata": {},
   "source": [
    "<a name=\"1-data-augmentation-vs-no-augmentation\"></a>\n",
    "## 1. Data Augmentation vs No Augmentation\n",
    "\n",
    "This section will be dedicated to assess whether the 2.5D model can outperform the 2D model. In order to do so, the first step is to run both resnets with the same configuration, architecture and data split. (only because the original ResNet was only trained for 50 epochs, and is therefore not directly comparable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd812c",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"11-concept-overview\"></a>\n",
    "### 1.1 Concept Overview  \n",
    "\n",
    "For detailed information on augmentations, please refer to directory `3 - resnetTesting`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a1abb",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"13-25d-execution-of-data-augmentation-vs-no-augmentation\"></a>\n",
    "### 1.2 2.5D Execution of Data Augmentation vs No Augmentation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2bfd34",
   "metadata": {},
   "source": [
    "The dictionary below will be used to save relevant metadata and models, with structure:\n",
    "\n",
    "```py\n",
    "\n",
    "results_aug[\"method\"] = [best_epoch, train_loss, best_val_loss, model]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c994217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_aug = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7d1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SliceID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101__CT-0002-0001.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101__CT-0002-0002.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101__CT-0002-0003.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101__CT-0002-0004.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101__CT-0002-0005.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SliceID  Class\n",
       "0  101__CT-0002-0001.npy      0\n",
       "1  101__CT-0002-0002.npy      0\n",
       "2  101__CT-0002-0003.npy      0\n",
       "3  101__CT-0002-0004.npy      0\n",
       "4  101__CT-0002-0005.npy      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instructions: type 0 → 2D Classification\n",
    "from newDimUtils import *\n",
    "\n",
    "# Loads the dataframe\n",
    "df_fibrosis = pd.read_pickle(r'..\\..\\..\\\\fibrosis_data.pkl')\n",
    "df_annotations = df_fibrosis.drop(columns=\"SliceData\")\n",
    "df_annotations[\"SliceID\"] = df_annotations[\"SliceID\"].astype(str) + \".npy\" # better for data loader\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33c7c2",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "#### <span style=\"color:Blue\"> 2D, no Augmentations </span>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9781de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FibrosisDataset(Dataset):\n",
    "        def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, albumentations=None, gauss=False):\n",
    "            self.img_labels = pd.read_csv(annotations_file)\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.albumentations = albumentations\n",
    "            self.gauss = gauss\n",
    "            self.number_images = 0\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # idx represents index\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "            if not os.path.exists(img_path): print(f\"Missing file: {img_path}\")\n",
    "            slice_id = self.img_labels.iloc[idx, 0]\n",
    "            patient_id = getPatientID(slice_id)\n",
    "\n",
    "            # Load the .npy file\n",
    "            image = np.load(img_path)\n",
    "            \n",
    "            #image = read_image(img_path)\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "            # Adds randomly selected gauss noise or blur\n",
    "            if self.gauss:\n",
    "                # Gaussian Noise\n",
    "                gauss_noise = image + np.random.normal(loc=0, scale=random.choice(range(10,40)), size=image.shape)\n",
    "                # Gaussian Blur\n",
    "                gauss_blur = gaussian_filter(image, sigma=(random.choice(range(10,16))/10)) \n",
    "                # Random Choice\n",
    "                image = random.choice((gauss_noise,gauss_blur))\n",
    "\n",
    "            # Guarantee compatibility\n",
    "            if self.gauss or self.albumentations: image = image.astype(np.float32)\n",
    "\n",
    "            # Applies necessary ResNet input transformations\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            \n",
    "            return image, label, patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cefbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "img_dir = r'..\\..\\..\\np_ROI_data'  # CSV with image filenames & labels\n",
    "annotations_file_train = r\"..\\trainTestCustom\\train.csv\"\n",
    "annotations_file_test = r\"..\\trainTestCustom\\test.csv\"\n",
    "annotations_file_val = r\"..\\trainTestCustom\\val.csv\"\n",
    "\n",
    "# Transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert (1, H, W) → (3, H, W)\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = FibrosisDataset(annotations_file_train, img_dir=img_dir, transform=transform, albumentations=None, gauss=False)\n",
    "test_dataset = FibrosisDataset(annotations_file_test, img_dir=img_dir, transform=transform)\n",
    "val_dataset = FibrosisDataset(annotations_file_val, img_dir=img_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ec1e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\2775595112.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(models_path,\"metadata_Noaug2D.pt\"))\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\2775595112.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_eval = torch.load((f\"{models_path}\"+\"resnet_noAug_2d.pkl\"))\n"
     ]
    }
   ],
   "source": [
    "models_path = \"..\\\\..\\\\..\\\\trainedResNets\\\\repeatingExperiment\\\\augNoAug\\\\2D\\\\\"\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "ans = str(input(\"Do you wish to run or read?\"))\n",
    "\n",
    "# Choice execution\n",
    "if ans == \"run\": \n",
    "    resnet_eval, best_epoch, custom_loss, custom_val_loss = trainResNet(train_dataset,val_dataset)\n",
    "\n",
    "elif ans == \"read\":\n",
    "    # Read file\n",
    "    checkpoint = torch.load(os.path.join(models_path,\"metadata_Noaug2D.pt\"))\n",
    "\n",
    "    # Load values\n",
    "    best_epoch = checkpoint[\"epoch\"]\n",
    "    custom_loss = checkpoint[\"train_loss\"]\n",
    "    custom_val_loss = checkpoint[\"val_loss\"]\n",
    "\n",
    "    resnet_eval = torch.load((f\"{models_path}\"+\"resnet_noAug_2d.pkl\"))\n",
    "\n",
    "\n",
    "else: print(\"Invalid answer, try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae77962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DID NOT SAVE\n"
     ]
    }
   ],
   "source": [
    "ans = str(input(\"Do you wish to save?\"))\n",
    "\n",
    "if ans == \"yes\": \n",
    "    torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'train_loss': custom_loss,\n",
    "    'val_loss': custom_val_loss\n",
    "}, os.path.join(models_path, 'metadata_Noaug2D.pt'))\n",
    "    \n",
    "    torch.save(resnet_eval, (f\"{models_path}\"+\"resnet_noAug_2d.pkl\"))\n",
    "\n",
    "else: print(\"DID NOT SAVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eceeb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to dict for result comparison\n",
    "results_aug[\"2d_noAug\"] = [best_epoch, custom_loss, custom_val_loss, resnet_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e26be",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "#### <span style=\"color:Blue\"> 2D, with Augmentations </span>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e073d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "img_dir = r'..\\..\\..\\np_ROI_data'  # CSV with image filenames & labels\n",
    "annotations_file_train = r\"..\\trainTestCustom\\train.csv\"\n",
    "annotations_file_test = r\"..\\trainTestCustom\\test.csv\"\n",
    "annotations_file_val = r\"..\\trainTestCustom\\val.csv\"\n",
    "\n",
    "# Transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert (1, H, W) → (3, H, W)\n",
    "])\n",
    "\n",
    "\n",
    "# Augmentations\n",
    "augment = A.Compose([\n",
    "    # Applies resize prior to augmentations\n",
    "    # Could hinder scan quality, but drastically improves training speed\n",
    "    A.Resize(224, 224),\n",
    "    # Rotate\n",
    "    A.Rotate(limit=(-350,30), p=0.8),\n",
    "    # Translate\n",
    "    A.Affine(translate_percent={\"x\":(-0.15,0.15), \"y\":{-0.23,0.25}},\n",
    "              rotate=0, scale=1, p=0.8),\n",
    "    # Shear\n",
    "    A.Affine(shear={\"x\":(-15,15), \"y\":(-15,15)},p=0.8)\n",
    "])\n",
    "\n",
    "# Randomized Gaussian Noise and Blur\n",
    "gauss = True\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = FibrosisDataset(annotations_file_train, img_dir=img_dir, transform=transform, albumentations=augment, gauss=gauss)\n",
    "test_dataset = FibrosisDataset(annotations_file_test, img_dir=img_dir, transform=transform)\n",
    "val_dataset = FibrosisDataset(annotations_file_val, img_dir=img_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee047db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\3071961570.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(models_path,\"metadata_aug2D.pt\"))\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\3071961570.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_eval = torch.load((f\"{models_path}\"+\"resnet_Aug_2d.pkl\"))\n"
     ]
    }
   ],
   "source": [
    "models_path = \"..\\\\..\\\\..\\\\trainedResNets\\\\repeatingExperiment\\\\augNoAug\\\\2D\\\\\"\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "ans = str(input(\"Do you wish to run or read?\"))\n",
    "\n",
    "# Choice execution\n",
    "if ans == \"run\": \n",
    "    resnet_eval, best_epoch, custom_loss, custom_val_loss = trainResNet(train_dataset,val_dataset)\n",
    "\n",
    "elif ans == \"read\":\n",
    "    # Read file\n",
    "    checkpoint = torch.load(os.path.join(models_path,\"metadata_aug2D.pt\"))\n",
    "\n",
    "    # Load values\n",
    "    best_epoch = checkpoint[\"epoch\"]\n",
    "    custom_loss = checkpoint[\"train_loss\"]\n",
    "    custom_val_loss = checkpoint[\"val_loss\"]\n",
    "\n",
    "    resnet_eval = torch.load((f\"{models_path}\"+\"resnet_Aug_2d.pkl\"))\n",
    "\n",
    "\n",
    "else: print(\"Invalid answer, try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed40193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DID NOT SAVE\n"
     ]
    }
   ],
   "source": [
    "ans = str(input(\"Do you wish to save?\"))\n",
    "\n",
    "if ans == \"yes\": \n",
    "    torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'train_loss': custom_loss,\n",
    "    'val_loss': custom_val_loss\n",
    "}, os.path.join(models_path, 'metadata_aug2D.pt'))\n",
    "    \n",
    "    torch.save(resnet_eval, (f\"{models_path}\"+\"resnet_Aug_2d.pkl\"))\n",
    "\n",
    "else: print(\"DID NOT SAVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025907eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to dict for result comparison\n",
    "results_aug[\"2d_Aug\"] = [best_epoch, custom_loss, custom_val_loss, resnet_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88befa67",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "#### <span style=\"color:teal\"> 2.5D, no Augmentations </span>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d802837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FibrosisDataset(Dataset):\n",
    "        def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, albumentations=None, gauss=False):\n",
    "            self.img_labels = pd.read_csv(annotations_file)\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.albumentations = albumentations\n",
    "            self.gauss = gauss\n",
    "            self.number_images = 0\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "        \n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # idx represents index\n",
    "\n",
    "            # Locates each image in the csv file\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "            if not os.path.exists(img_path): print(f\"Missing file: {img_path}\")\n",
    "\n",
    "            # Fetches entire slice name\n",
    "            slice_id = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "            # Parses patient ID for each slice\n",
    "            patient_id = getPatientID(slice_id)\n",
    "\n",
    "            # Get current slice info and class\n",
    "            curr_img = np.load(img_path)\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "\n",
    "            # This function can fetch any additional slice\n",
    "            def load_image(i):\n",
    "                row = self.img_labels.iloc[i]\n",
    "                path = os.path.join(self.img_dir, row[0])\n",
    "                img = np.load(path).astype(np.float32)\n",
    "                label = row[1]\n",
    "                return img, label, row[0]\n",
    "\n",
    "            \n",
    "            # Fetches previous slice\n",
    "            if (idx > 0) and getPatientID(self.img_labels.iloc[idx - 1, 0]) == patient_id:\n",
    "                prev_img, _, _ = load_image(idx - 1)\n",
    "            else: prev_img = curr_img  # Duplicates slice if it's the first, uses as previous \n",
    "            \n",
    "            # Try to get next slice\n",
    "            if (idx < len(self.img_labels) - 1) and getPatientID(self.img_labels.iloc[idx + 1, 0]) == patient_id:\n",
    "                next_img, _, _ = load_image(idx + 1)\n",
    "            else: next_img = curr_img  # Duplicates slice if it's the last, uses as next \n",
    "            \n",
    "\n",
    "            # Finally, stacks them into RGB: shape → (3, H, W)\n",
    "            image = np.stack([prev_img, curr_img, next_img], axis=0)\n",
    "\n",
    "            # Reorder: shape → (H, W, 3)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Now it looks like an RGB image\n",
    "\n",
    "            # Adds randomly selected gauss noise or blur\n",
    "            if self.gauss:\n",
    "                # Gaussian Noise\n",
    "                gauss_noise = image + np.random.normal(loc=0, scale=random.choice(range(10,40)), size=image.shape)\n",
    "                # Gaussian Blur\n",
    "                gauss_blur = gaussian_filter(image, sigma=(random.choice(range(10,16))/10)) \n",
    "                # Random Choice\n",
    "                image = random.choice((gauss_noise,gauss_blur))\n",
    "\n",
    "            # Guarantee compatibility\n",
    "            if self.gauss or self.albumentations: image = image.astype(np.float32)\n",
    "\n",
    "            # Applies necessary ResNet input transformations\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            \n",
    "            return image, label, patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ac4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "img_dir = r'..\\..\\..\\np_ROI_data'  # CSV with image filenames & labels\n",
    "annotations_file_train = r\"..\\trainTestCustom\\train.csv\"\n",
    "annotations_file_test = r\"..\\trainTestCustom\\test.csv\"\n",
    "annotations_file_val = r\"..\\trainTestCustom\\val.csv\"\n",
    "\n",
    "# Transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = FibrosisDataset(annotations_file_train, img_dir=img_dir, transform=transform, albumentations=None, gauss=False)\n",
    "test_dataset = FibrosisDataset(annotations_file_test, img_dir=img_dir, transform=transform)\n",
    "val_dataset = FibrosisDataset(annotations_file_val, img_dir=img_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "482855fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-----------------------------*\n",
      "|         Using cuda          |\n",
      "*-----------------------------*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/55 [00:00<?, ?it/s]C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  path = os.path.join(self.img_dir, row[0])\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = row[1]\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return img, label, row[0]\n",
      "Training...: 100%|██████████| 55/55 [00:20<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/90], Train loss: 0.483119\n",
      "Validation loss: 0.475432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/90], Train loss: 0.457045\n",
      "Validation loss: 0.468997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:11<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/90], Train loss: 0.435293\n",
      "Validation loss: 0.463947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/90], Train loss: 0.416435\n",
      "Validation loss: 0.459606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:11<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/90], Train loss: 0.399552\n",
      "Validation loss: 0.455841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:11<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/90], Train loss: 0.389202\n",
      "Validation loss: 0.452512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/90], Train loss: 0.371150\n",
      "Validation loss: 0.449559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/90], Train loss: 0.361734\n",
      "Validation loss: 0.446594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/90], Train loss: 0.349418\n",
      "Validation loss: 0.443639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/90], Train loss: 0.337411\n",
      "Validation loss: 0.441020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:11<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/90], Train loss: 0.326593\n",
      "Validation loss: 0.438306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/90], Train loss: 0.319514\n",
      "Validation loss: 0.435859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/90], Train loss: 0.313120\n",
      "Validation loss: 0.433089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/90], Train loss: 0.306586\n",
      "Validation loss: 0.431316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/90], Train loss: 0.294289\n",
      "Validation loss: 0.429134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/90], Train loss: 0.289050\n",
      "Validation loss: 0.427102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/90], Train loss: 0.278258\n",
      "Validation loss: 0.424904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/90], Train loss: 0.270588\n",
      "Validation loss: 0.422974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/90], Train loss: 0.264410\n",
      "Validation loss: 0.421092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/90], Train loss: 0.284107\n",
      "Validation loss: 0.419335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/90], Train loss: 0.250776\n",
      "Validation loss: 0.417956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/90], Train loss: 0.246918\n",
      "Validation loss: 0.416136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/90], Train loss: 0.242818\n",
      "Validation loss: 0.414994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/90], Train loss: 0.239749\n",
      "Validation loss: 0.413978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/90], Train loss: 0.235599\n",
      "Validation loss: 0.412737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/90], Train loss: 0.225207\n",
      "Validation loss: 0.411674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/90], Train loss: 0.221615\n",
      "Validation loss: 0.410591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/90], Train loss: 0.213329\n",
      "Validation loss: 0.409527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/90], Train loss: 0.209675\n",
      "Validation loss: 0.408638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/90], Train loss: 0.209938\n",
      "Validation loss: 0.407600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/90], Train loss: 0.203453\n",
      "Validation loss: 0.406964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/90], Train loss: 0.199905\n",
      "Validation loss: 0.405959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/90], Train loss: 0.224766\n",
      "Validation loss: 0.405606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/90], Train loss: 0.189769\n",
      "Validation loss: 0.405039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/90], Train loss: 0.216547\n",
      "Validation loss: 0.404541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/90], Train loss: 0.188160\n",
      "Validation loss: 0.403784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/90], Train loss: 0.179577\n",
      "Validation loss: 0.402627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/90], Train loss: 0.171336\n",
      "Validation loss: 0.402556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/90], Train loss: 0.168897\n",
      "Validation loss: 0.402127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/90], Train loss: 0.174865\n",
      "Validation loss: 0.402029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/90], Train loss: 0.162063\n",
      "Validation loss: 0.402271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/90], Train loss: 0.159486\n",
      "Validation loss: 0.401610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/90], Train loss: 0.156825\n",
      "Validation loss: 0.401872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/90], Train loss: 0.150644\n",
      "Validation loss: 0.401723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/90], Train loss: 0.151165\n",
      "Validation loss: 0.401394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/90], Train loss: 0.147737\n",
      "Validation loss: 0.401358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/90], Train loss: 0.146924\n",
      "Validation loss: 0.401207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/90], Train loss: 0.140737\n",
      "Validation loss: 0.401566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/90], Train loss: 0.140849\n",
      "Validation loss: 0.401137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/90], Train loss: 0.138399\n",
      "Validation loss: 0.401028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/90], Train loss: 0.139445\n",
      "Validation loss: 0.400431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/90], Train loss: 0.129273\n",
      "Validation loss: 0.400646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/90], Train loss: 0.130329\n",
      "Validation loss: 0.400918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/90], Train loss: 0.128012\n",
      "Validation loss: 0.401367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/90], Train loss: 0.126818\n",
      "Validation loss: 0.401168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/90], Train loss: 0.127222\n",
      "Validation loss: 0.401886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/90], Train loss: 0.125016\n",
      "Validation loss: 0.402203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/90], Train loss: 0.116402\n",
      "Validation loss: 0.402456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/90], Train loss: 0.113648\n",
      "Validation loss: 0.402970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/90], Train loss: 0.111015\n",
      "Validation loss: 0.402545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/90], Train loss: 0.111616\n",
      "Validation loss: 0.402660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/90], Train loss: 0.107763\n",
      "Validation loss: 0.403010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/90], Train loss: 0.107243\n",
      "Validation loss: 0.403673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/90], Train loss: 0.103180\n",
      "Validation loss: 0.403884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:09<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/90], Train loss: 0.102916\n",
      "Validation loss: 0.404136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/90], Train loss: 0.096540\n",
      "Validation loss: 0.404579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/90], Train loss: 0.100583\n",
      "Validation loss: 0.404619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/90], Train loss: 0.104320\n",
      "Validation loss: 0.405262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/90], Train loss: 0.092131\n",
      "Validation loss: 0.405554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/90], Train loss: 0.091323\n",
      "Validation loss: 0.405510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/90], Train loss: 0.092252\n",
      "Validation loss: 0.406593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/90], Train loss: 0.092630\n",
      "Validation loss: 0.408044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/90], Train loss: 0.085193\n",
      "Validation loss: 0.409915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/90], Train loss: 0.082294\n",
      "Validation loss: 0.410336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/90], Train loss: 0.085404\n",
      "Validation loss: 0.410058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:11<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/90], Train loss: 0.082251\n",
      "Validation loss: 0.410402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/90], Train loss: 0.079243\n",
      "Validation loss: 0.411119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/90], Train loss: 0.077176\n",
      "Validation loss: 0.411935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/90], Train loss: 0.079675\n",
      "Validation loss: 0.412803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/90], Train loss: 0.116600\n",
      "Validation loss: 0.413718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/90], Train loss: 0.072165\n",
      "Validation loss: 0.414494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/90], Train loss: 0.090093\n",
      "Validation loss: 0.414695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/90], Train loss: 0.070617\n",
      "Validation loss: 0.415357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/90], Train loss: 0.071153\n",
      "Validation loss: 0.416035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/90], Train loss: 0.069438\n",
      "Validation loss: 0.416465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/90], Train loss: 0.068461\n",
      "Validation loss: 0.417403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/90], Train loss: 0.069409\n",
      "Validation loss: 0.417357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/90], Train loss: 0.064538\n",
      "Validation loss: 0.417833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/90], Train loss: 0.070493\n",
      "Validation loss: 0.418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 55/55 [00:10<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/90], Train loss: 0.061633\n",
      "Validation loss: 0.419894\n"
     ]
    }
   ],
   "source": [
    "models_path = \"..\\\\..\\\\..\\\\trainedResNets\\\\repeatingExperiment\\\\augNoAug\\\\2_5D\\\\\"\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "ans = str(input(\"Do you wish to run or read?\"))\n",
    "\n",
    "# Choice execution\n",
    "if ans == \"run\": \n",
    "    resnet_eval, best_epoch, custom_loss, custom_val_loss = trainResNet(train_dataset,val_dataset)\n",
    "\n",
    "elif ans == \"read\":\n",
    "    # Read file\n",
    "    checkpoint = torch.load(os.path.join(models_path,\"metadata_Noaug2_5D.pt\"))\n",
    "\n",
    "    # Load values\n",
    "    best_epoch = checkpoint[\"epoch\"]\n",
    "    custom_loss = checkpoint[\"train_loss\"]\n",
    "    custom_val_loss = checkpoint[\"val_loss\"]\n",
    "\n",
    "    resnet_eval = torch.load((f\"{models_path}\"+\"resnet_noAug_2_5d.pkl\"))\n",
    "\n",
    "\n",
    "else: print(\"Invalid answer, try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d47887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = str(input(\"Do you wish to save?\"))\n",
    "\n",
    "if ans == \"yes\": \n",
    "    torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'train_loss': custom_loss,\n",
    "    'val_loss': custom_val_loss\n",
    "}, os.path.join(models_path, 'metadata_Noaug2D.pt'))\n",
    "    \n",
    "    torch.save(resnet_eval, (f\"{models_path}\"+\"resnet_noAug_2d.pkl\"))\n",
    "\n",
    "else: print(\"DID NOT SAVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c027845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_aug[\"2_5d_noAug\"] = [best_epoch, custom_loss, custom_val_loss, resnet_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479e4de",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "#### <span style=\"color:teal\"> 2.5D, with Augmentations </span>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9844e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "img_dir = r'..\\..\\..\\np_ROI_data'  # CSV with image filenames & labels\n",
    "annotations_file_train = r\"..\\trainTestCustom\\train.csv\"\n",
    "annotations_file_test = r\"..\\trainTestCustom\\test.csv\"\n",
    "annotations_file_val = r\"..\\trainTestCustom\\val.csv\"\n",
    "\n",
    "# Transformations \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "])\n",
    "\n",
    "\n",
    "# Augmentations\n",
    "augment = A.Compose([\n",
    "    # Applies resize prior to augmentations\n",
    "    # Could hinder scan quality, but drastically improves training speed\n",
    "    A.Resize(224, 224),\n",
    "    # Rotate\n",
    "    A.Rotate(limit=(-350,30), p=0.8),\n",
    "    # Translate\n",
    "    A.Affine(translate_percent={\"x\":(-0.15,0.15), \"y\":{-0.23,0.25}},\n",
    "              rotate=0, scale=1, p=0.8),\n",
    "    # Shear\n",
    "    A.Affine(shear={\"x\":(-15,15), \"y\":(-15,15)},p=0.8)\n",
    "])\n",
    "\n",
    "# Randomized Gaussian Noise and Blur\n",
    "gauss = True\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = FibrosisDataset(annotations_file_train, img_dir=img_dir, transform=transform, albumentations=augment, gauss=gauss)\n",
    "test_dataset = FibrosisDataset(annotations_file_test, img_dir=img_dir, transform=transform)\n",
    "val_dataset = FibrosisDataset(annotations_file_val, img_dir=img_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db27e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-----------------------------*\n",
      "|         Using cuda          |\n",
      "*-----------------------------*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/55 [00:00<?, ?it/s]C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  path = os.path.join(self.img_dir, row[0])\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = row[1]\n",
      "C:\\Users\\hasht\\AppData\\Local\\Temp\\ipykernel_15232\\20686485.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return img, label, row[0]\n",
      "Training...: 100%|██████████| 55/55 [01:20<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/90], Train loss: 0.650851\n",
      "Validation loss: 0.660502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 15/55 [00:23<01:01,  1.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Choice execution\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ans == \u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m: \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     resnet_eval, best_epoch, custom_loss, custom_val_loss = \u001b[43mtrainResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ans == \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Read file\u001b[39;00m\n\u001b[32m     12\u001b[39m     checkpoint = torch.load(os.path.join(models_path,\u001b[33m\"\u001b[39m\u001b[33mmetadata_aug2_5D.pt\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\Desktop\\Cloned Repositories\\AI-for-Interstitial-Lung-Disease-Classification\\4 - modelDevelopment\\4.4 - 2.5D\\newDimUtils.py:268\u001b[39m, in \u001b[36mtrainResNet\u001b[39m\u001b[34m(train_dataset, val_dataset, num_epochs, batch_size, lr, patience, improve_min)\u001b[39m\n\u001b[32m    262\u001b[39m running_val_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# --------------- Weight updates ---------------\u001b[39;00m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# Iterates over each image in dataset, updates weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Applies ADAM \u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mFibrosisDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     62\u001b[39m gauss_noise = image + np.random.normal(loc=\u001b[32m0\u001b[39m, scale=random.choice(\u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m,\u001b[32m40\u001b[39m)), size=image.shape)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Gaussian Blur\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m gauss_blur = \u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Random Choice\u001b[39;00m\n\u001b[32m     66\u001b[39m image = random.choice((gauss_noise,gauss_blur))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:425\u001b[39m, in \u001b[36mgaussian_filter\u001b[39m\u001b[34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) > \u001b[32m0\u001b[39m:\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m         \u001b[38;5;28minput\u001b[39m = output\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:323\u001b[39m, in \u001b[36mgaussian_filter1d\u001b[39m\u001b[34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[32m    322\u001b[39m weights = _gaussian_kernel1d(sigma, order, lw)[::-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hasht\\anaconda3\\envs\\fibrosis\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:180\u001b[39m, in \u001b[36mcorrelate1d\u001b[39m\u001b[34m(input, weights, axis, output, mode, cval, origin)\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInvalid origin; origin must satisfy \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    177\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m(len(weights)-1) // 2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    179\u001b[39m mode = _ni_support._extend_mode_to_code(mode)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[43m_nd_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "models_path = \"..\\\\..\\\\..\\\\trainedResNets\\\\repeatingExperiment\\\\augNoAug\\\\2_5D\\\\\"\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "ans = str(input(\"Do you wish to run or read?\"))\n",
    "\n",
    "# Choice execution\n",
    "if ans == \"run\": \n",
    "    resnet_eval, best_epoch, custom_loss, custom_val_loss = trainResNet(train_dataset,val_dataset)\n",
    "\n",
    "elif ans == \"read\":\n",
    "    # Read file\n",
    "    checkpoint = torch.load(os.path.join(models_path,\"metadata_aug2_5D.pt\"))\n",
    "\n",
    "    # Load values\n",
    "    best_epoch = checkpoint[\"epoch\"]\n",
    "    custom_loss = checkpoint[\"train_loss\"]\n",
    "    custom_val_loss = checkpoint[\"val_loss\"]\n",
    "\n",
    "    resnet_eval = torch.load((f\"{models_path}\"+\"resnet_Aug_2_5d.pkl\"))\n",
    "\n",
    "\n",
    "else: print(\"Invalid answer, try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61463c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DID NOT SAVE\n"
     ]
    }
   ],
   "source": [
    "ans = str(input(\"Do you wish to save?\"))\n",
    "\n",
    "if ans == \"yes\": \n",
    "    torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'train_loss': custom_loss,\n",
    "    'val_loss': custom_val_loss\n",
    "}, os.path.join(models_path, 'metadata_aug2_5D.pt'))\n",
    "    \n",
    "    torch.save(resnet_eval, (f\"{models_path}\"+\"resnet_Aug_2_5d.pkl\"))\n",
    "\n",
    "else: print(\"DID NOT SAVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to dict for result comparison\n",
    "results_aug[\"2d_Aug\"] = [best_epoch, custom_loss, custom_val_loss, resnet_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab348fa5",
   "metadata": {},
   "source": [
    "<a name=\"12-threshold-selection-and-model-choice\"></a>\n",
    "### 1.3 Threshold Selection and Model Choice  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1568a1",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"14-comparison-with-2d\"></a>\n",
    "### 1.4 Comparison with 2D  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80c9b2",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"2-patient-wise-classification-methods\"></a>\n",
    "## 2. Patient-wise Classification Methods\n",
    "\n",
    "<a name=\"21-concept-overview\"></a>\n",
    "### 2.1 Concept Overview  \n",
    "\n",
    "<a name=\"22-threshold-selection-and-model-choice\"></a>\n",
    "### 2.2 Threshold Selection and Model Choice  \n",
    "\n",
    "<a name=\"23-25d-execution-of-patient-wise-classification-methods\"></a>\n",
    "### 2.3 2.5D Execution of Patient-wise Classification Methods  \n",
    "\n",
    "<a name=\"24-comparison-with-2d\"></a>\n",
    "### 2.4 Comparison with 2D  \n",
    "\n",
    "\n",
    "<a name=\"3-slice-level-feature-wise-classification\"></a>\n",
    "## 3. Slice-level Feature-wise Classification\n",
    "\n",
    "<a name=\"31-concept-overview\"></a>\n",
    "### 3.1 Concept Overview  \n",
    "\n",
    "<a name=\"32-threshold-selection-and-model-choice\"></a>\n",
    "### 3.2 Threshold Selection and Model Choice  \n",
    "\n",
    "<a name=\"33-25d-execution-of-slice-level-feature-wise-classification\"></a>\n",
    "### 3.3 2.5D Execution of Slice-level Feature-wise Classification  \n",
    "\n",
    "<a name=\"34-comparison-with-2d\"></a>\n",
    "### 3.4 Comparison with 2D  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibrosis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
